---
title: "Predicting Self-Rated Mental Health Based on Demographic and Family Traits"
author: "James Bao, Alan Chen, Xinyi Zhang, Zidong Yang"
date: "10/19/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggcorrplot)
```

The code used to generate this RMarkdown file can be found at https://github.com/cindyzhang99/sta304_ps3/blob/main/sta304_ps3.Rmd.


# Abstract
- An abstract is included and appropriately pitched to a general audience.
- The abstract answers: what was done, what was found, and why this matters (all at a high level).
- If your abstract is longer than four sentences then you need to think a lot about whether it is too long. It may be fine (there are always exceptions) but you should probably have a good reason.


# Introduction
- The introduction is self-contained and tells a reader everything they need to know, including putting it into a broader context.
- Your introduction should provide a bit of broader context to motivate the reader, as well as providing a bit more detail about what you're interested in, what you did, what you found, why it's important, etc.
- A reader should be able to read only your introduction and have a good idea about the research that you carried out.
- It would be rare that you would have tables or figures in your introduction (again there are always exceptions but think deeply about whether yours is one).
- It must outline the structure of the report.


# Data
The dataset we used in our modeling is the 2017 General Social Survey (Family cycle). The following sections will discuss how the data was collected, what the key features of the dataset are, and what the data looks like.

## Data Collection
From February 1, 2017 to November 30, 2017, Statistics Canada gathered data on the Canadian family unit by conducting voluntary telephone interviews. Their target population was all non-institutionalized individuals living in Canada, aged 15 or older. Cross-sectional sampling was conducted in a two-stage design. 

The stratified simple random sampling method was used in the first stage. Here, the sampling frame consisted of telephone numbers from the Census grouped as households using data from Statistic Canada's dwelling frame. Strata were formed at the census metropolitan area (CMA) level and at the province level (i.e., large CMAs formed their own stratum, smaller CMAs were grouped together, and the non-CMA regions of each province were grouped together), forming a total of 27 non-overlapping strata. Finally, households were sampled randomly from each stratum such that the number sampled units from each stratum corresponded to the population sizes of each stratum. To reiterate, the sampled population for this first stage was the chosen households from each stratum. 
The stratified simple random sampling method was also used in the second stage. Here, the sampling frame was a list of household members, aged 15 and older, from the households selected in the first stage. Then, one individual was randomly selected from each household, forming the sampled population. Approximately 43,000 individuals were contacted to participate in the survey.

Overall, the surveying method using two-stage simple random stratified sampling is effective in generating a sample that is geographically representative of the Canadian population. In addition to estimates about the Canadian population at large, the stratified sampling method also allows estimates to be made about subpopulations (at the province level). 

Statistics Canada reported that the non-response rate was 47.6%. To reduce the effects of non-response bias, survey responses were adjusted based on the demographic characteristics of households that were non-responsive (by pulling their information from the 2016 Census). This ensures that the discrepancy between the target population and survey responses resulting from non-response is minimized. Furthermore, for the Family cycle of the GSS, responses were also adjusted for income and household size to make more accurate survey estimates for the variables of interest.

Statistics Canada did not disclose the true cost of conducting the survey but we can make some speculations based on the available information about their field work methodology. Surveying was conducted using Computer Assisted Telephone Interviewing (CATI) wherein interviewers read aloud the computerized questionnaire and immediately record the respondent's answers. Although this allows for a reduction in costs compared to traditional in-person surveying, labor costs still include time spent computerizing the survey, training interviewers, and having interviewers administer the questionnaire. Other labor costs include designing the questionnaire and surveying methodology as well as conducting quality control (data consistency was checked by the CATI system during surveying and unresolved inconsistencies were handled afterwards by support staff). Non-labor costs likely included paying for equipment, phone service, offices, and so forth. Again, although we don't have exact costs, we can conclude that the time and costs associated with conducting the GSS is a clear reason why it is only administered once a year.

Per the report on the 2017 GSS from Statistics Canada, extensive research and testing was conducted when designing the questionnaire. Consequently, a major strength of the questionnaire is that it contains focused questions that comprehensively and extensively capture the subject of interest (the Canadian family). Upon reading through the questionnaire made available by Statistics Canada, the wording of each question is precise and clear, leaving little room for ambiguity. Additionally, another strength of the survey is that a vast majority of questions were objective (dates, events, counts) removing potential response biases that occur with subjective questions. (Not all questions were objective however, in fact the variable of interest we will model in subsequent sections consists of subjective responses.) On the other hand, because of the specificity of the questions, the survey is very long with several dozens sections and several questions per section. Furthermore, as a result of the large scope of the target population, many questions in the survey did not apply to a large majority of respondents (e.g., number of grandchildren, questions about additional marriages, etc.). The data collected is also incomplete because participants were given the option to refuse to answer or answer "I don't know" to each question since participation was voluntary.

Overall, the surveying methodology and distributed questionnaire were carefully designed in the interest of collecting accurate, representative data wherever possible.

## Data Characteristics
The full dataset of responses to the 2017 General Social Survey (Family cycle) contains 20,602 observations for over 400 variables relating to the Canadian family. A large reason for our choice to use this dataset is because it is the most recent GSS cycle available for modeling. Other benefits of this dataset have been previously touched upon in the previous section. Namely, the data was checked for consistency in real time by the CATI system (as well as by survey support staff) so there is a certain measure of accuracy that other survey results lack. Additionally, the stratified simple random sampling method used to distribute the survey suggests that the results are representative of the Canadian population to some degree (in the geographical sense at the very least). A major weakness of the data is that it is not complete because of the voluntary nature of the surveying.

In the interest of space, we will only discuss the variables in the dataset that are relevant to our model. The variable we aim to predict is self_rated_mental_health while the factors that we chose to inform this prediction are age, sex, marital_status, and self_rated_health. We chose these factors based on the demographic information mentioned in mental health statistics (age, sex, and health) and based on what we suspected might contribute to mental health in the context of family composition (marital status, has children). More explicitly, here are the chosen variables we used from the original dataset:

* agedc (renamed to age): the exact age of the respondent (in decimals) at the time of the survey
* sex (sex): sex of the respondent, the options being "Male" or "Female"
* marstat (marital_status): marital status of the respondent, the options being "Single, never married", "Married", "Living common-law", "Separated" (but still legally married), "Divorced", or "Widowed"
* totchdc (total_children): total number of children reported by respondent
* srh_110 (self_rated_health): self-rated physical health, the options being "Excellent", "Very good", "Good", "Fair", and "Poor"
* srh_115 (self_rated_mental_health): self-rated mental health, the options being "Excellent", "Very good", "Good", "Fair", and "Poor"

For age, there is a similar variable in the original dataset that uses only natural numbers (agec), however, we chose to use agedc (and renamed it to "age") in the interest of accuracy. There are many variables related to marriage in the original dataset (totunc: total number of marriage and common-law unions, nmarevrc: number of marriages the respondent has had, etc.) but they don't capture the same scope of information as marstat (renamed to "marital_status") does (for example, being divorced or widowed is not reflected in those variables). Consequently, we chose marital_status as opposed to the other available variables related to marriage. We transformed totchdc (renamed to "total_children") into a binary variable has_children (if total children is 0, has_children equals FALSE, if total children is greater than 0, has_children equals TRUE). For the other three variables we use (sex, self_rated_health or srh_110 in the original dataset, and self_rated_mental_health or srh_115 in the original dataset), there are no similar equivalents.

We will refer to the variables by their renamed identifiers for the rest of the paper.

## Data Visualization
Specific instructions on how to download the 2017 GSS dataset can be found in the header of the gss_cleaning.R file found here (https://github.com/cindyzhang99/sta304_ps3/blob/main/gss_cleaning/gss_cleaning.R).

We cleaned the original 2017 GSS dataset using gss_cleaning.R, producing gss_cleaned.csv (with variables renamed accordingly).

```{r message=FALSE, echo=FALSE}
library(tidyverse)

# load the cleaned dataset
data <- read_csv("gss_cleaned.csv")

# choose pertinent variables
data <- data %>% select(age, sex, marital_status, total_children, self_rated_health, 
                        self_rated_mental_health)
# transform total_children into binary variable has_children
data$has_children <- as.logical(data$total_children) 
# drop incomplete rows from the dataset
data<-data[complete.cases(data),]
# choose subset of data with valid mental health self-rating
data<-data[!grepl("Don't know", data$self_rated_mental_health),]
# view distributions of the variables of interest
# summary table with statistics for age
summary(data$age)
# distribution of age as a histogram
ggplot(data, aes(x=age)) + geom_histogram(position="identity", binwidth = 10) +
  xlab("Age (years)") +
  ylab("Number of Respondents") +
  ggtitle("Figure 1: Distribution of the age of respondents.")

# total number of observations in the dataset
total_count = nrow(data)

# summary table with counts for sex
tibble_sex <- data.frame(table(data$sex)) %>%
  rename(
    sex = Var1,
    count = Freq
  )
tibble_sex
# distribution of sex as a bar graph in percentages
ggplot(tibble_sex, aes(x = sex, y = count/total_count)) + 
  geom_bar(stat = "identity") +
  geom_text(aes(label = paste0(round(count/total_count*100), "%")),
            color="white",
            position = position_stack(vjust = 0.5)) +
  xlab("Sex") +
  ylab("Percentage of Respondents") +
  ggtitle("Figure 2: Distribution of the sex of respondents in percentages.")

# summary table with counts for marital status
tibble_marital_status <- data.frame(table(data$marital_status)) %>%
  rename(
    marital_status = Var1,
    count = Freq
  )
# manually changing the order of factors in the following output table and graph
tibble_marital_status$marital_status <- factor(tibble_marital_status$marital_status, 
                                               levels = c("Single, never married",
                                                          "Married", "Living common-law", 
                                                          "Separated", "Divorced",
                                                          "Widowed"))
tibble_marital_status
# distribution of marital status as a bar graph in percentages
ggplot(tibble_marital_status, aes(x = marital_status, y = count/total_count)) + 
  geom_bar(stat = "identity") +
  geom_text(aes(label = paste0(round(count/total_count*100), "%")),
            color="white",
            position = position_stack(vjust = 0.5)) +
  xlab("Marital Status") +
  ylab("Percentage of Respondents") +
  ggtitle("Figure 3: Distribution of the marital status of respondents in percentages.")

# summary table with counts for marital status
tibble_children <- data.frame(table(data$has_children)) %>%
  rename(
    has_children = Var1,
    count = Freq
  )
tibble_children
# distribution of marital status as a bar graph in percentages
ggplot(tibble_children, aes(x = has_children, y = count/total_count)) + 
  geom_bar(stat = "identity") +
  geom_text(aes(label = paste0(round(count/total_count*100), "%")),
            color="white",
            position = position_stack(vjust = 0.5)) +
  xlab("Has Children") +
  ylab("Percentage of Respondents") +
  ggtitle("Figure 4: Distribution of respondents with and without children.")

# summary table with counts for self-rated health
tibble_health <- data.frame(table(data$self_rated_health)) %>%
  rename(
    health = Var1,
    count = Freq
  )
# manually changing the order of factors in the following output table and graph
tibble_health$health <- factor(tibble_health$health, 
                               levels = c("Poor", "Fair", "Good", "Very good",
                                          "Excellent", "Don't know"))
tibble_health
# distribution of self-rated health as a bar graph in percentages
ggplot(tibble_health, aes(x = health, y = count/total_count)) + 
  geom_bar(stat = "identity") +
  geom_text(aes(label = paste0(round(count/total_count*100), "%")),
            color="white",
            position = position_stack(vjust = 0.5)) +
  xlab("Self-rated Health") +
  ylab("Percentage of Respondents") +
  ggtitle("Figure 5: Distribution of the self-rated health of respondents in percentages.")

# summary table with counts for self-rated mental health
tibble_mental_health <- data.frame(table(data$self_rated_mental_health)) %>%
  rename(
    mental_health = Var1,
    count = Freq
  )
# manually changing the order of factors in the following output table and graph
tibble_mental_health$mental_health <- factor(tibble_mental_health$mental_health, 
                                             levels = c("Poor", "Fair", "Good", 
                                                        "Very good", "Excellent", 
                                                        "Don't know"))
tibble_mental_health
# distribution of self-rated mental health as a bar graph in percentages
ggplot(tibble_mental_health, aes(x = mental_health, y = count/total_count)) + 
  geom_bar(stat = "identity") +
  geom_text(aes(label = paste0(round(count/total_count*100), "%")),
            color="white",
            position = position_stack(vjust = 0.5)) +
  xlab("Self-rated Mental Health") +
  ylab("Percentage of Respondents") +
  ggtitle("Figure 6: Self-rated mental health of respondents in percentages.")
```
Out of the respondents, approximately 54% were female and 46% were male (Figure 2). Most of the respondents were in their 60's and 70's, while the next most common demographic were respondents in their 40's and 50's (Figure 1). This preliminary look at the dataset is fairly consistent with Canadian demographics according to the 2016 Census, with the female response being approximately 3% higher than expected and the average age being approximately 11 years older than expected (the average Canadian age is 41 while the average respondent age was 52). This older demographic makes sense as individuals less than 15 years of age were not eligible to respond to the survey and are therefore not represented here. 

Of the 20,602 responses, 194 rows were dropped if the value for a variable was not available. For our purposes of attempting to model mental health, we consequently removed these individuals from the dataset we used in generating our model. Furthermore, according to Figure 5, the responses are heavily skewed towards positive responses, with 30% of respondents replying with 'Excellent' and 34% replying 'Very good'. 28% rated their mental health as 'Good' with the remaining 8% split 6 to 2 with regards to 'Fair' and 'Poor', respectively. These results overwhelmingly indicate that a large proportion of the sampled population feel that their mental is very strong. However, we proceed with modeling in the next section of this paper to better understand the contribution of the chosen demographic and family factors on self-rated mental. Is there a pattern of traits that separate "Excellent", "Very good", and "Good" ratings? What are the biggest distinctions between an individual with good mental health and poor mental health? These are some of the motivating questions we strive to answer with our model.

# Model
The purpose of the model is to predict a person's self-rated mental health based our selected factors of age, sex, marital status, and self-rated physical health. Since self-rated mental health is a categorical data type in this dataset, the task at its core is a classification problem.

## Model Selection
Some models that we considered were linear regression, naive Bayes, binary logistic regression, and multinomial logistic regression. To begin, linear regression is not suitable because it is often difficult to find an accurate linear relationship between predictors and categories, not to mention the fact that linear regression is more suitable when the dependent variable is continuous. Naive Bayes is a viable option since it is able to handle classification of more than two categories using joint probability and Bayes' Theorem. However, naive Bayes only works well under the assumption that the explanatory variables are independent, but this is often not the case. Given the context of the data, it is highly anticipated that the characteristics of a person are correlated in some way or another (e.g., age showing a correlation with self-rated physical health).

In addition, generative models (e.g., Naive Bayes) have a higher asymptotic error than discriminative models (e.g., logistic regression), but they approach the asymptotic error faster. In other words, discriminative models tend to perform better given a large enough dataset while generative models will perform better on small dataset as they learn faster. Since the dataset is large, choosing a discriminative model would be more appropriate for this task.

It is also important to note that the dependent variable has more than two categories. One way to handle this is to group multiple categories together so that there are only two categories. Then we would be able to use binary logistic regression to model the relationship. While this simplifies the complexity of implementing the model itself, there will be a loss in information from merging classes, impacting the strength of the conclusions we can draw. Another option to handle multi-classification is to use multinomial logistic regression which is an extension of binary logistic regression. The basic idea of this approach is to create a binary logistic regression model for each class. Each binary logistic regression model will do a one-versus-rest prediction for the corresponding class. The class with the highest probability will be the output prediction of the multinomial model. One of the caveats of this approach is that even more data is required to provide enough information for all binary logistic regression models for each class; otherwise, this method is prone to overfitting. This is less of a concern in this case because the size of the dataset is large enough to predict 5 classes. Thus, we chose multinomial logistic regression as our model for this task.

As described in the Data Characteristics section of this report, we chose four features (age, sex, marital_status, and self_rated_health) based on their perceived impact on self-rated mental health (self_rated_mental_health). We chose age as a continuous factor as opposed to the discrete version (where age is only given in whole numbers) in the interest of accuracy and being able to provide the model with the most fine-grained ata. Sex and marital status are categorical variables due to the nature of the information they provide (you're either single, married, in a common-law partnership, separated, divorced, or widowed, there is no status that exists in-between any of these options). Although self-rated health and self-rated mental health exists in real life on a continuous scale, due to the nature of responses gathered by the 2017 GSS, self_rated_health and self_rated_mental are categorical variables with possible values such as Poor, Fair, Good, Very good, and Excellent. There is no way for us to transform the categorical responses into a continuous variable that remains true to the data collected and there isn't any need to do so because we adjusted the selection of our model accordingly.

## Mathematical Model
We fully derive the mathetical representation of the multinomial logistic regression model in the Appendix. In the interest of space, here we will just provide the equations we derived for the probability of each outcome:

$$ \Pr(Y_i = 1) = \frac{e^{\boldsymbol{\beta_1 \cdot X_i}}}{1 + \sum^{4}_{k=1} e^{\boldsymbol{\beta_k \cdot X_i}}} $$
$$ \Pr(Y_i = 2) = \frac{e^{\boldsymbol{\beta_2 \cdot X_i}}}{1 + \sum^{4}_{k=1} e^{\boldsymbol{\beta_k \cdot X_i}}} $$
$$ \Pr(Y_i = 3) = \frac{e^{\boldsymbol{\beta_3 \cdot X_i}}}{1 + \sum^{4}_{k=1} e^{\boldsymbol{\beta_k \cdot X_i}}} $$
$$ \Pr(Y_i = 4) = \frac{e^{\boldsymbol{\beta_4 \cdot X_i}}}{1 + \sum^{4}_{k=1} e^{\boldsymbol{\beta_k \cdot X_i}}}$$
$$ \Pr(Y_i = 5) = \frac{1}{1 + \sum^{4}_{k=1} e^{\boldsymbol{\beta_k \cdot X_i}}} $$
We will explain each variable that appears in the equations above (again, please see the Appendix for a more natural definition of each variable as we derive these equations). 
$Y_i$ represents the outcome of the response variable for the $i$th observation. Since we have a total of 5 possible outcomes (Poor, Fair, Good, Very Good, and Excellent), we represent each of them as 1, 2, 3, 4, and 5 in the interest of space. 

$\boldsymbol{\beta_k}$ is the row vector with elements that are the coefficients for the explanatory variables for the $k$th outcome. More explicitly, $\boldsymbol{\beta_k} = [\beta_{0,k}, \beta_{1,k}, \beta_{2,k}, \beta_{3,k}, \beta_{4,k}, \beta_{5,k}]$ where $\beta_{0,k}$ is the intercept for the $k$th outcome, $\beta_{1,k}$ is the coefficient for the first explanatory variable (age) for the $k$th outcome, $\beta_{2,k}$ is the coefficient for the second explanatory variable (sex) for the $k$th outcome, $\beta_{3,k}$ is the coefficient for the third explanatory variable (marital_status) for the $k$th outcome, $\beta_{4,k}$ is the coefficient for the fourth explanatory variable (has_children) for the $k$th outcome, and $\beta_{5,k}$ is the coefficient for the fifth explanatory variable (self_rated_health) for the $k$th outcome.

$\boldsymbol{x_i}$ is the row vector of explanatory variables for the $i$th observation. Specifically, $\boldsymbol{x_i} = [1, x_{1,i}, x_{2,i}, x_{3,i}, x_{4,i}, x_{5,i}]$ where $x_{1,i}$ is the value of the first explanatory variable (age) for the $i$th observation, $x_{2, i}$ is the value of the second explanatory variable (sex) for the $i$th observation, and so on.

Therefore, the first equation represents the probability that the self_rated_mental_health of the $i$th observation is Poor given values for age, sex, marital_status, has_children, and self_rated_health. The other 4 equations can be interpreted in a similar manner.

## Running the Model
To estimate the model, we use the multinom function from the library nnet written in the programming language R. Our script is run using the software RStudio.

```{r message=FALSE, warning=FALSE}
# install.packages("nnet")
library(nnet)
# install.packages("Metrics")
library(Metrics)

# shuffle rows of data tibble for cross-validation
# for reproducibility
set.seed(42)
# generate randomized indices for rows
shuffled_indices <- sample(total_count)
# shuffle data tibble accordingly
data <- data[shuffled_indices,]
# set boundary between training and testing
boundary = as.integer(total_count * 0.8)
# take subset of dataset to form training dataset
training_dataset = data[0:boundary,]

# run model where self_rated_mental_health is response variable and age, sex, 
# marital status, has children, and self rated health are explanatory variables
model <- nnet::multinom(self_rated_mental_health ~ age + sex + marital_status + has_children + 
                          self_rated_health, data = training_dataset)
```
Our model successfully converged after 60 iterations on the training dataset to a final negative log-likelihood value of 18179. Although this a really large number, this is not too bad considering we have over 16300 observations in the training dataset and the negative log-likelihood is equal to the likelihood we would observe the specific dataset (after taking the log and multiplying by -1). 

We did not run into any diagnostic issues when running our model.

As we hinted at with the phrase "training dataset", we conducted cross-validation to check our model. The procedure and the accuracy of our model is covered in the next section (Results).

# Results
We will graph the relationship between mental health and each of the explanatory variables as well as discuss the results of our model.
```{r}
grouped_bar_chart <- function(data, xlab, ylab, title){
  ggplot(data, 
       aes(y=grouped, x=value, fill=Rating, label=Rating))+
  geom_bar(stat="identity",position="dodge", width=0.8) +
  scale_x_continuous(ylab) + 
  scale_y_discrete(xlab) + 
  ggtitle(title)
}
# graph distribution of self-rated mental health for each gender

# data parsing into format I want for chart
grouped <- data %>%
  count(sex, self_rated_mental_health) %>%
  rename(
    count=n
  )
#total number of votes
total_vote <- aggregate(grouped$count, 
                        by=list(sex=grouped$sex), FUN=sum)

#process data into desired graphing format
grouped<-left_join(grouped, total_vote, by="sex") %>%
  rename(total=x) %>%
  mutate(value=count/total) %>%
  rename(grouped=sex, Rating=self_rated_mental_health)
# manually order bars in bar graph
grouped$Rating <- factor(grouped$Rating, 
                               levels = c("Poor", "Fair", "Good", "Very good",
                                          "Excellent", "Don't know"))
grouped
grouped_bar_chart(grouped, "Sex", "Percentage", 
                  "Figure 7: Distribution of Self-Rated Mental Health Responses by Sex")

```
```{r}
# graph marital status vs distribution of self rated mental health
#data parsing into format I want for chart
grouped <- data %>%
  count(marital_status, self_rated_mental_health) %>%
  rename(
    count=n
  )

#total number of votes
total_vote <- aggregate(grouped$count, 
                        by=list(marital_status=grouped$marital_status), FUN=sum)

#process data into desired graphing format
grouped<-left_join(grouped, total_vote, by="marital_status") %>%
  rename(total=x) %>%
  mutate(value=count/total) %>%
  rename(grouped=marital_status, Rating=self_rated_mental_health)
# manually order bars in bar graph
grouped$Rating <- factor(grouped$Rating, 
                               levels = c("Poor", "Fair", "Good", "Very good",
                                          "Excellent", "Don't know"))
# manually categories on y-axis
grouped$grouped <- factor(grouped$grouped, 
                               levels = c("Single, never married",
                                                          "Married", "Living common-law", 
                                                          "Separated", "Divorced",
                                                          "Widowed"))
grouped
grouped_bar_chart(grouped, "Marital Status", 
                  "Percentage", 
                  "Figure 8: Self-Rated Mental Health Against Marital Status")

```
```{r}
# graph distribution of self-rated mental health for each gender

# data parsing into format I want for chart
grouped <- data %>%
  count(has_children, self_rated_mental_health) %>%
  rename(
    count=n
  )
#total number of votes
total_vote <- aggregate(grouped$count, 
                        by=list(has_children=grouped$has_children), FUN=sum)

#process data into desired graphing format
grouped<-left_join(grouped, total_vote, by="has_children") %>%
  rename(total=x) %>%
  mutate(value=count/total) %>%
  rename(grouped=has_children, Rating=self_rated_mental_health)
# manually order bars in bar graph
grouped$Rating <- factor(grouped$Rating, 
                               levels = c("Poor", "Fair", "Good", "Very good",
                                          "Excellent", "Don't know"))
grouped_bar_chart(grouped, "Has Children", "Percentage", 
                  "Figure 9: Self-Rated Mental Health With and Without Children")
```
```{r}
# graph distribution of self-rated mental health for each gender

# data parsing into format I want for chart
grouped <- data %>%
  count(self_rated_health, self_rated_mental_health) %>%
  rename(
    count=n
  )
#total number of votes
total_vote <- aggregate(grouped$count, 
                        by=list(self_rated_health=grouped$self_rated_health), FUN=sum)

#process data into desired graphing format
grouped<-left_join(grouped, total_vote, by="self_rated_health") %>%
  rename(total=x) %>%
  mutate(value=count/total) %>%
  rename(grouped=self_rated_health, Rating=self_rated_mental_health)
# manually order bars in bar graph
grouped$Rating <- factor(grouped$Rating, 
                               levels = c("Poor", "Fair", "Good", "Very good",
                                          "Excellent", "Don't know"))
# manually categories on y-axis
grouped$grouped <- factor(grouped$grouped, 
                               levels = c("Poor", "Fair", "Good", "Very good",
                                          "Excellent", "Don't know"))
grouped_bar_chart(grouped, "Self-Rated Physical Health", "Percentage", 
                  "Figure 10: Self-Rated Mental Health Against Physical Health")
```

```{r}
summary(model)
```
Here, we have output a summary of the coefficients of our model. Recall the mathematical representation of our multinomial logistic regression model. The equations used to compute probabilities for each outcome only need coefficients for non-pivots which is why the outcome Excellent (which serves as the pivot in our model) doesn't appear in the table. Another interesting thing to note is that because the variables sex, marital_status, has_children, and self_rated_health are categorical, they are represented using dummy variables in our model.

```{r}
z <- summary(model)$coefficients/summary(model)$standard.errors
(1 - pnorm(abs(z), 0, 1)) * 2
```

Here we conduct a two-tailed z-test on the coefficients. To set up our analysis in the discussion section, we will define the null and alternative hypothesis here. The null hypothesis for each coefficient is that the coefficient is equal to 0, i.e., there is no difference in likelihood between one of the four values of the response variable ("Fair", "Good", "Poor", or "Very good") compared to the value "Excellent" for the given explanatory variable. The alternative hypothesis is therefore that the coefficient is not equal to zero, i.e., that there is a difference between the odds of the value of the response variable being a non-pivot outcome ("Fair", "Good", "Poor", or "Very good") and the odds of the response variable being "Excellent". Setting the significance level at 0.05, if the p-value for the coefficient of a certain explanatory variable is less than 0.05, then we can reject the null hypothesis and conclude there is statistically significant evidence that there is a difference in odds between the response variable and "Excellent" given the explanatory variable.


```{r}
# take subset of dataset to form testing dataset
testing_dataset = data[boundary:total_count,]
testing_dataset = testing_dataset[complete.cases(testing_dataset), ]
# predict what is the likelihood of each outcome for each observation in the testing dataset
testing_probabilities <- predict(model, newdata = testing_dataset, "probs")

# identify the predicted outcome based on which probability is the largest
# find the column index with the largest probability
column_index <- max.col(testing_probabilities, tie="random")
# form a list of outcomes with column names for testing dataset
testing_predictions <- colnames(testing_probabilities)[column_index]
testing_ground_truth <- testing_dataset %>% pull(self_rated_mental_health)
accuracy(testing_ground_truth, testing_predictions)
```

Additionally, we checked the predictions of our model by conducting cross validation. We split the shuffled dataset into training and testing subsets (an 80-20 split, respectively). Then, we trained the model using only the training data and made predictions on the testing data. Finally, we compared the model's predictions to the ground truth values for self-rated mental health for the test set. Our predictions for the test set had an accuracy of 54.9%. 

# Discussion
As depicted in Figure 7, the main difference between male and female self-rated mental health is the gap between the percentages of "Excellent" and "Very good" responses. Namely, 28% of female respondents reported their mental health was "Excellent" while 32% of male respondents reported the same answer.  Furthermore, 35% of female respondents reported their mental health was "Very good" while only 33% of male respondents reported the same answer. Overall, a larger percentage of males reported that their mental health is eitiher "Very good" or "Excellent" and there isn't as much of a difference in the distribution of those responses as was observed in female responses. This suggests that females are less likely to consider their mental health as being "Excellent" compared to males.

A smaller percentage of respondents rated their mental health as poor if they were married (0.7%) or living in a common-law relationship (1.1%) (Figure 8). In order of the percentage of "Poor" responses received, it goes Widowed (1.8%), Divorced (2.7%), Single Never Married (2.8%), and Separated (3.4%). Interestingly, individuals who were widowed were much less likely to rate their mental health as poor compared to individuals who were either divorced, never married, or separated. Furthermore, married and living in a common-law relationship all received the highest response rates for "Excellent" at 32.1% and 30.1%, respectively. These results seem to strongly indicate that the bond between partners have an impact on mental health and lacking that bond may be detrimental to one's mental health.

Surprisingly, there is not a significant difference between self-rated mental health with and without children (Figure 9). 

Lastly, there seems to be the largest variation in responses for self-rated mental health with respect to self-rated physical health (Figure 10). In fact, there appears to be a direct correlation between self-ratings of mental health and self-ratings of physical health. The largest percentage of "Excellent" ratings for mental health occurred in the cohort with "Excellent" physical health, the largest rating of "Very good" mental health occurred in the cohort with "Very good" physical health, and so forth. The opposite trend also exists where smallest rating of "Poor" mental health occurs in the cohort with "Excellent" physical health, and so on. This is evidence that there is a strong correlation between physical health and mental health despite being fundamentally different aspects of one's life. That is, an individual with self-evaluated "Excellent" physical health likely has a corresponding "Excellent" self-rating of mental health. This could be due to a variety of factors, for example having higher self-confidence in their physical fitness, experiencing the benefits of regular exercise on their mental health, and so forth. 

By analyzing the coefficients of our model, we can determine what kind of effect certain each variable has on an individual's self-rating of their mental health. For example, being married makes individuals less likely to report "Poor" mental health compared to "Excellent" mental health by -0.97 logarithmic units. However, being married has half the effect on the odds of having a "Fair" mental health self-rating compared to "Excellent" and close to no affect on differentiating between "Good" and "Excellent" and "Very good" and "Excellent." Noticeably, a strongest correlation is found between self-rated physical health and self-rated mental health as mentioned previously. An individual marking themselves as having excellent self-rated physical health decreases their logarithmic chances of having poor self-rated mental health by 5 compared to their chances of having excellent self-rated mental. Variables such as age and number of kids have a limited effect on a person's mental health rating. 

The two-tailed z-test conducted on the coefficients indicates unsurprisingly that the most statistically significant coefficients are found in the self-rated mental health explanatory variables, with all coefficients being statistically significant for the explanatory variable excellent self-rated physical health and 3/4 coefficients being statistically significant for the explanatory variable very good self-rated physical health. Although some coeffcients such as those for age and sex are also statistically significant, the values of the coefficients themselves are not very large (close to 0 for age and within 0.3 logarithmic units of 0 for sex). Therefore, the tests appear to reflect that there is little difference between the odds for non-pivot outcomes and the "Excellent" outcome given the explanatory variable age and sex.

Lastly, we will discuss the accuracy of our model. Compared to random predictions which would have an accuracy of only 20% (since there are five possible outcomes for the response variable), our cross validation results indicate that our model performs at least twice as well. Furthermore, this accuracy is calculated based on exact matches between predicted and ground truth values. If we considered predictions of Very good to be close enough to ground truth values of Excellent, the accuracy of our model will be much higher. 

```{r}
map <- data.frame(find=c('Excellent', 'Very good', 'Good', 'Fair', 'Poor'),replace=c('Excellent', 'Excellent', 'Good', 'Poor', 'Poor'))
testing_ground_truth_simplified <- as.character(map[match(testing_ground_truth, map$find), "replace"])
testing_predictions_simplified <- as.character(map[match(testing_predictions, map$find), "replace"])
accuracy(testing_ground_truth_simplified, testing_predictions_simplified)
```
We gain a sense of the relative accuracy of our model by mapping "Very good" values to "Excellent" values and "Fair" values to "Poor" values. This has a 67.2% accuracy which again reinforces the idea that the model has identified non-trivial relationships between the explanatory and response variables. 

In summary, although we have found that our model is able to make non-trivial predictions about mental health self-ratings given demographic and family traits for an individual, we also determined that not all of our chosen explanatory variables are equally important in making that prediction. 

# Weaknesses and future work

Our survey had many weaknesses, such as the fact that we chose to analyze a variable that is very hard to predict, prone to bias and relative to the respondents experience towards mental health. Another large weakness was the data excluded youths aged 15 and younger. This effects our results significantly because youths mental illness is a prominent issue as half of all mental health issues begin by the age of 15 and the lack of this data does not allow us to represent mental health thoroughly. This was a weakness we were aware of and knew it would affect our outcome. However, we were still curious to see how the responses would go and determine if the results can lead to insights. We also were not able to spend time to include all the variables we wanted. Variables such as income, detailed family situations and living situations were things we planned on adding to our model but due to time and covariance concerns we were not able to integrate them into our model. This would be part of our future plans in order to build a more encompassing model. Furthermore, we hope to gain less bias information on an individuals mental health by utilizing mental health surveys dedicated to measuring an individuals mental health with less bias. 

# Appendix

## Derivation of the mathematical representation of the multinomial logistic regression model
Recall that the multinomial logistic regression consists of several binary logistic regression models. Like binary logistic regression, multinomial logistic regression predicts the probability that the $i$th observation has outcome $k$ using the following function:

$$f(k, i) = \beta_{0,k} + \beta_{1,k}x_{1,i} + \beta_{2,k}x_{2,i} + ... + \beta_{M,k}x_{M,i}$$
where $\beta_{m,k}$ is the coefficient for the $m$th explanatory variable and the $k$th outcome while $x_{m, i}$ is the value of the $m$th explanatory variable for the $i$th observation. In our case, we have $M=5$ (age, sex, marital_status, has_children self_rated_health) explanatory variables so the function as applicable to our model is:  

$$f(k, i) = \beta_{0,k} + \beta_{1,k}x_{1,i} + \beta_{2,k}x_{2,i} + \beta_{3,k}x_{3,i} + \beta_{4,k}x_{4,i} + \beta_{5,k}x_{5,i}$$
Note that we can represent $\beta_{0,k}, \beta_{1,k}, \beta_{2,k}, \beta_{3,k}, \beta_{4,k}, \beta_{5,k}$ and $1, x_{1,i}, x_{2,i}, x_{3,i}, x_{4,i}, x_{5,i}$  as row vectors $\boldsymbol{\beta_k}$ and $\boldsymbol{x_i}$, respectively. Then, the function can be simplified as follows:
$$f(k, i) = \boldsymbol{\beta_k} \cdot \boldsymbol{x_i}$$
where we take the dot product of the two row vectors we just defined.

As previously mentioned, the multinomial logistic regression model is a series of binary logistic regressions where the probability of each outcome of the response variable (self-rated mental health) is regressed against a chosen pivot outcome. Let $Y_i$ represent the outcome of the response variable for the $i$th observation. We have a total of 5 possible outcomes (Poor, Fair, Good, Very Good, and Excellent represented as 1, 2, 3, 4, and 5, respectively). Let's choose the last outcome (Excellent or 5) as the pivot. In mathematical notation, this is:
$$ \ln{\frac{\Pr(Y_i = 1)}{\Pr(Y_i = 5)}} = \boldsymbol{\beta_1 \cdot X_i} $$
$$ \ln{\frac{\Pr(Y_i = 2)}{\Pr(Y_i = 5)}} = \boldsymbol{\beta_2 \cdot X_i} $$
$$\ln{\frac{\Pr(Y_i = 3)}{\Pr(Y_i = 5)}} = \boldsymbol{\beta_3 \cdot X_i} $$
$$\ln{\frac{\Pr(Y_i = 4)}{\Pr(Y_i = 5)}} = \boldsymbol{\beta_4 \cdot X_i} $$

Then, we solve for the probabilities by exponentiating both sides:
$$ \Pr(Y_i = 1) = \Pr(Y_i = 5) \cdot e^{\boldsymbol{\beta_1 \cdot X_i}} $$
$$ \Pr(Y_i = 2) = \Pr(Y_i = 5) \cdot e^{\boldsymbol{\beta_2 \cdot X_i}} $$
$$ \Pr(Y_i = 3) = \Pr(Y_i = 5) \cdot e^{\boldsymbol{\beta_3 \cdot X_i}}$$
$$ \Pr(Y_i = 4) = \Pr(Y_i = 5) \cdot e^{\boldsymbol{\beta_4 \cdot X_i}}$$

The probability of the pivot outcome can be calculated because we know that the probability of all outcomes must sum to 1:
$$ \Pr(Y_i = 5) = 1 - \left(\Pr(Y_i = 5) \cdot e^{\boldsymbol{\beta_1 \cdot X_i}} + \Pr(Y_i = 5) \cdot e^{\boldsymbol{\beta_2 \cdot X_i}} + \Pr(Y_i = 5) \cdot e^{\boldsymbol{\beta_3 \cdot X_i}} + \Pr(Y_i = 5) \cdot e^{\boldsymbol{\beta_4 \cdot X_i}}\right) $$
$$ 1 = \Pr(Y_i = 5) + \Pr(Y_i = 5) \cdot e^{\boldsymbol{\beta_1 \cdot X_i}} + \Pr(Y_i = 5) \cdot e^{\boldsymbol{\beta_2 \cdot X_i}} + \Pr(Y_i = 5) \cdot e^{\boldsymbol{\beta_3 \cdot X_i}} + \Pr(Y_i = 5) \cdot e^{\boldsymbol{\beta_4 \cdot X_i}} $$
$$ 1 = \Pr(Y_i = 5) \left(1 + e^{\boldsymbol{\beta_1 \cdot X_i}} + e^{\boldsymbol{\beta_2 \cdot X_i}} + e^{\boldsymbol{\beta_3 \cdot X_i}} + e^{\boldsymbol{\beta_4 \cdot X_i}} \right) $$
$$ 1 = \Pr(Y_i = 5) \left(1 + \sum^{4}_{k=1} e^{\boldsymbol{\beta_k \cdot X_i}} \right) $$
$$ \Pr(Y_i = 5) = \frac{1}{1 + \sum^{4}_{k=1} e^{\boldsymbol{\beta_k \cdot X_i}}} $$
Having the expression for $\Pr(Y_i = 4)$, we can represent the probabilities of the other outcomes as follows:
$$ \Pr(Y_i = 1) = \frac{e^{\boldsymbol{\beta_1 \cdot X_i}}}{1 + \sum^{4}_{k=1} e^{\boldsymbol{\beta_k \cdot X_i}}} $$
$$ \Pr(Y_i = 2) = \frac{e^{\boldsymbol{\beta_2 \cdot X_i}}}{1 + \sum^{4}_{k=1} e^{\boldsymbol{\beta_k \cdot X_i}}} $$
$$ \Pr(Y_i = 3) = \frac{e^{\boldsymbol{\beta_3 \cdot X_i}}}{1 + \sum^{4}_{k=1} e^{\boldsymbol{\beta_k \cdot X_i}}} $$
$$ \Pr(Y_i = 4) = \frac{e^{\boldsymbol{\beta_4 \cdot X_i}}}{1 + \sum^{4}_{k=1} e^{\boldsymbol{\beta_k \cdot X_i}}}$$
$$ \Pr(Y_i = 5) = \frac{1}{1 + \sum^{4}_{k=1} e^{\boldsymbol{\beta_k \cdot X_i}}} $$


# References
Interview method/survey size: https://www.statcan.gc.ca/eng/survey/household/4501
Detailed information about GSS 2017: https://www23.statcan.gc.ca/imdb/p2SV.pl?Function=getSurvey&Id=335816
Questionnaire: https://www23.statcan.gc.ca/imdb/p3Instr.pl?Function=assembleInstr&lang=en&Item_Id=335815#qb345205
Mental health statistics: https://www.camh.ca/en/Driving-Change/The-Crisis-is-Real/Mental-Health-Statistics
Discriminative vs Generative Classifiers (Naive Bayes vs lostic regression): https://ai.stanford.edu/~ang/papers/nips01-discriminativegenerative.pdf
Age and sex https://www12.statcan.gc.ca/census-recensement/2016/dp-pd/hlt-fst/as/Table.cfm?Lang=E&T=21