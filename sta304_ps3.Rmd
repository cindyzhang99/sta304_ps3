---
title: "Predicting Self-Rated Mental Health Based on Demographic and Family Traits"
author: "James Bao, Alan Chen, Xinyi Zhang, Zidong Yang"
date: "10/19/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

The code used to generate this RMarkdown file can be found at https://github.com/cindyzhang99/sta304_ps3/blob/main/sta304_ps3.Rmd.


# Abstract
- An abstract is included and appropriately pitched to a general audience.
- The abstract answers: what was done, what was found, and why this matters (all at a high level).
- If your abstract is longer than four sentences then you need to think a lot about whether it is too long. It may be fine (there are always exceptions) but you should probably have a good reason.


# Introduction
- The introduction is self-contained and tells a reader everything they need to know, including putting it into a broader context.
- Your introduction should provide a bit of broader context to motivate the reader, as well as providing a bit more detail about what you're interested in, what you did, what you found, why it's important, etc.
- A reader should be able to read only your introduction and have a good idea about the research that you carried out.
- It would be rare that you would have tables or figures in your introduction (again there are always exceptions but think deeply about whether yours is one).
- It must outline the structure of the report.


# Data
The dataset we used in our modeling is the 2017 General Social Survey (Family cycle). The following sections will discuss how the data was collected, what the key features of the dataset are, and what the data looks like.

## Data Collection
From February 1, 2017 to November 30, 2017, Statistics Canada gathered data on the Canadian family unit by conducting voluntary telephone interviews. Their target population was all non-institutionalized individuals living in Canada, aged 15 or older. Cross-sectional sampling was conducted in a two-stage design. 

The stratified simple random sampling method was used in the first stage. Here, the sampling frame consisted of telephone numbers from the Census grouped as households using data from Statistic Canada's dwelling frame. Strata were formed at the census metropolitan area (CMA) level and at the province level (i.e., large CMAs formed their own stratum, smaller CMAs were grouped together, and the non-CMA regions of each province were grouped together), forming a total of 27 non-overlapping strata. Finally, households were sampled randomly from each stratum such that the number sampled units from each stratum corresponded to the population sizes of each stratum. To reiterate, the sampled population for this first stage was the chosen households from each stratum. 

The stratified simple random sampling method was also used in the second stage. Here, the sampling frame was a list of household members, aged 15 and older, from the households selected in the first stage. Then, one individual was randomly selected from each household, forming the sampled population. Approximately 43,000 individuals were contacted to participate in the survey.

Overall, the surveying method using two-stage simple random stratified sampling is effective in generating a sample that is geographically representative of the Canadian population. In addition to estimates about the Canadian population at large, the stratified sampling method also allows estimates to be made about subpopulations (at the province level). 

Statistics Canada reported that the non-response rate was 47.6%. To reduce the effects of non-response bias, survey responses were adjusted based on the demographic characteristics of households that were non-responsive (by pulling their information from the 2016 Census). This ensures that the discrepancy between the target population and survey responses resulting from non-response is minimized. Furthermore, for the Family cycle of the GSS, responses were also adjusted for income and household size to make more accurate survey estimates for the variables of interest.

Statistics Canada did not disclose the true cost of conducting the survey but we can make some speculations based on the available information about their field work methodology. Surveying was conducted using Computer Assisted Telephone Interviewing (CATI) wherein interviewers read aloud the computerized questionnaire and immediately record the respondent's answers. Although this allows for a reduction in costs compared to traditional in-person surveying, labor costs still include time spent computerizing the survey, training interviewers, and having interviewers administer the questionnaire. Other labor costs include designing the questionnaire and surveying methodology as well as conducting quality control (data consistency was checked by the CATI system during surveying and unresolved inconsistencies were handled afterwards by support staff). Non-labor costs likely included paying for equipment, phone service, offices, and so forth. Again, although we don't have exact costs, we can conclude that the time and costs associated with conducting the GSS is a clear reason why it is only administered once a year.

Per the report on the 2017 GSS from Statistics Canada, extensive research and testing was conducted when designing the questionnaire. Consequently, a major strength of the questionnaire is that it contains focused questions that comprehensively and extensively capture the subject of interest (the Canadian family). Upon reading through the questionnaire made available by Statistics Canada, the wording of each question is precise and clear, leaving little room for ambiguity. Additionally, another strength of the survey is that a vast majority of questions were objective (dates, events, counts) removing potential response biases that occur with subjective questions. (Not all questions were objective however, in fact the variable of interest we will model in subsequent sections consists of subjective responses.) On the other hand, because of the specificity of the questions, the survey is very long with several dozens sections and several questions per section. Furthermore, as a result of the large scope of the target population, many questions in the survey did not apply to a large majority of respondents (e.g., number of grandchildren, questions about additional marriages, etc.). The data collected is also incomplete because participants were given the option to refuse to answer or answer "I don't know" to each question since participation was voluntary.

Overall, the surveying methodology and distributed questionnaire were carefully designed in the interest of collecting accurate, representative data wherever possible.

## Data Characteristics
The full dataset of responses to the 2017 General Social Survey (Family cycle) contains 20,602 observations for over 400 variables relating to the Canadian family. A large reason for our choice to use this dataset is because it is the most recent GSS cycle available for modeling. Other benefits of this dataset have been previously touched upon in the previous section. Namely, the data was checked for consistency in real time by the CATI system (as well as by survey support staff) so there is a certain measure of accuracy that other survey results lack. Additionally, the stratified simple random sampling method used to distribute the survey suggests that the results are representative of the Canadian population to some degree (in the geographical sense at the very least). A major weakness of the data is that it is not complete because of the voluntary nature of the surveying.

In the interest of space, we will only discuss the variables in the dataset that are relevant to our model. The variable we aim to predict is self_rated_mental_health while the factors that we chose to inform this prediction are age, sex, marital_status, and self_rated_health. We chose these factors based on the demographic information mentioned in mental health statistics (age, sex, and health) and based on what we suspected might contribute to mental health in the context of family composition (marital status). More explicitly, here is what information the chosen variables in the dataset represent:

* age (agedc in the original dataset): the exact age of the respondent (in decimals) at the time of the survey
* sex (sex): sex of the respondent, the options being "Male" or "Female"
* marital_status (marstat): marital status of the respondent, the options being "Single, never married", "Married", "Living common-law", "Separated" (but still legally married), "Divorced", or "Widowed"
* self_rated_health (srh_110): self-rated physical health, the options being "Excellent", "Very good", "Good", "Fair", and "Poor"
* self_rated_mental_health (srh_115): self-rated mental health, the options being "Excellent", "Very good", "Good", "Fair", and "Poor"

For age, there is a similar variable in the original dataset that uses only natural numbers (agec), however, we chose to use agedc (and renamed it to "age") in the interest of accuracy. There are many variables related to marriage in the original dataset (totunc: total number of marriage and common-law unions, nmarevrc: number of marriages the respondent has had, etc.) but they don't capture the same scope of information as marital_status does (for example, being divorced or widowed is not reflected in those variables). Consequently, we chose marital status as opposed to the other available variables related to marriage. For the other three variables we use (sex, self_rated_health or srh_110 in the original dataset, and self_rated_mental_health or srh_115 in the original dataset), there are no similar equivalents.

## Data Visualization
Specific instructions on how to download the 2017 GSS dataset can be found in the header of the gss_cleaning.R file found here (https://github.com/cindyzhang99/sta304_ps3/blob/main/gss_cleaning/gss_cleaning.R).

We cleaned the original 2017 GSS dataset using gss_cleaning.R, producing gss_cleaned.csv.

```{r message=FALSE, echo=FALSE}
library(tidyverse)

# load the cleaned dataset
data <- read_csv("gss_cleaned.csv")

# choose pertinent variables
data <- data %>% select(age, sex, marital_status, self_rated_health, 
                        self_rated_mental_health)

# choose subset of data with valid mental health self-rating
data<-data[!grepl("Don't know", data$self_rated_mental_health),]

# view distributions of the variables of interest
# summary table with statistics for age
summary(data$age)
# distribution of age as a histogram
ggplot(data, aes(x=age)) + geom_histogram(position="identity", binwidth = 10) +
  xlab("Age (years)") +
  ylab("Number of Respondents") +
  ggtitle("Figure 1: Distribution of the age of respondents.")

# total number of observations in the dataset
total_count = nrow(data)

# summary table with counts for sex
tibble_sex <- data.frame(table(data$sex)) %>%
  rename(
    sex = Var1,
    count = Freq
  )
tibble_sex
# distribution of sex as a bar graph in percentages
ggplot(tibble_sex, aes(x = sex, y = count/total_count)) + 
  geom_bar(stat = "identity") +
  geom_text(aes(label = paste0(round(count/total_count*100), "%")),
            color="white",
            position = position_stack(vjust = 0.5)) +
  xlab("Sex") +
  ylab("Percentage of Respondents") +
  ggtitle("Figure 2: Distribution of the sex of respondents in percentages.")

# summary table with counts for marital status
tibble_marital_status <- data.frame(table(data$marital_status)) %>%
  rename(
    marital_status = Var1,
    count = Freq
  )
# manually changing the order of factors in the following output table and graph
tibble_marital_status$marital_status <- factor(tibble_marital_status$marital_status, 
                                               levels = c("Single, never married",
                                                          "Married", "Living common-law", 
                                                          "Separated", "Divorced",
                                                          "Widowed"))
tibble_marital_status
# distribution of marital status as a bar graph in percentages
ggplot(tibble_marital_status, aes(x = marital_status, y = count/total_count)) + 
  geom_bar(stat = "identity") +
  geom_text(aes(label = paste0(round(count/total_count*100), "%")),
            color="white",
            position = position_stack(vjust = 0.5)) +
  xlab("Marital Status") +
  ylab("Percentage of Respondents") +
  ggtitle("Figure 3: Distribution of the marital status of respondents in percentages.")

# summary table with counts for self-rated health
tibble_health <- data.frame(table(data$self_rated_health)) %>%
  rename(
    health = Var1,
    count = Freq
  )
# manually changing the order of factors in the following output table and graph
tibble_health$health <- factor(tibble_health$health, 
                               levels = c("Poor", "Fair", "Good", "Very good",
                                          "Excellent", "Don't know"))
tibble_health
# distribution of self-rated health as a bar graph in percentages
ggplot(tibble_health, aes(x = health, y = count/total_count)) + 
  geom_bar(stat = "identity") +
  geom_text(aes(label = paste0(round(count/total_count*100), "%")),
            color="white",
            position = position_stack(vjust = 0.5)) +
  xlab("Self-rated Health") +
  ylab("Percentage of Respondents") +
  ggtitle("Figure 4: Distribution of the self-rated health of respondents in percentages.")

# summary table with counts for self-rated mental health
tibble_mental_health <- data.frame(table(data$self_rated_mental_health)) %>%
  rename(
    mental_health = Var1,
    count = Freq
  )
# manually changing the order of factors in the following output table and graph
tibble_mental_health$mental_health <- factor(tibble_mental_health$mental_health, 
                                             levels = c("Poor", "Fair", "Good", 
                                                        "Very good", "Excellent", 
                                                        "Don't know"))
tibble_mental_health
# distribution of self-rated mental health as a bar graph in percentages
ggplot(tibble_mental_health, aes(x = mental_health, y = count/total_count)) + 
  geom_bar(stat = "identity") +
  geom_text(aes(label = paste0(round(count/total_count*100), "%")),
            color="white",
            position = position_stack(vjust = 0.5)) +
  xlab("Self-rated Mental Health") +
  ylab("Percentage of Respondents") +
  ggtitle("Figure 5: Self-rated mental health of respondents in percentages.")
```
Out of the respondents, approximately 54% were female and 46% were male (Figure 2). Most of the respondents were in their 60's and 70's, while the next most common demographic were respondents in their 40's and 50's (Figure 1). This preliminary look at the dataset is fairly consistent with Canadian demographics according to the 2016 Census, with the female response being approximately 3% higher than expected and the average age being approximately 11 years older than expected (the average Canadian age is 41 while the average respondent age was 52). This older demographic makes sense as individuals less than 15 years of age were not eligible to respond to the survey and are therefore not represented here. 

Of the 20,602 respondents, 57 individuals declined to provide a self-rating of their mental health. For our purposes of attempting to model mental health, we consequently removed these individuals from the dataset we used in generating our model. Furthermore, according to Figure 5, the responses are heavily skewed towards positive responses, with 30% of respondents replying with 'Excellent' and 34% replying 'Very good'. 28% rated their mental health as 'Good' with the remaining 8% split 6 to 2 with regards to 'Fair' and 'Poor', respectively. These results overwhelmingly indicate that a large proportion of the sampled population feel that their mental is very strong. However, we proceed with modeling in the next section of this paper to better understand the contribution of the chosen demographic and family factors on self-rated mental. Is there a pattern of traits that separate "Excellent", "Very good", and "Good" ratings? What are the biggest distinctions between an individual with good mental health and poor mental health? These are some of the motivating questions we strive to answer with our model.

# Model
The purpose of the model is to predict a person's self-rated mental health based our selected factors of age, sex, marital status, and self-rated physical health. Since self-rated mental health is a categorical data type in this dataset, the task at its core is a classification problem.

## Model Selection
Some models that we considered were linear regression, naive Bayes, binary logistic regression, and multinomial logistic regression. To begin, linear regression is not suitable because it is often difficult to find an accurate linear relationship between predictors and categories, not to mention the fact that linear regression is more suitable when the dependent variable is continuous. Naive Bayes is a viable option since it is able to handle classification of more than two categories using joint probability and Bayes' Theorem. However, naive Bayes only works well under the assumption that the explanatory variables are independent, but this is often not the case. Given the context of the data, it is highly anticipated that the characteristics of a person are correlated in some way or another (e.g., age showing a correlation with self-rated physical health).

In addition, generative models (e.g., Naive Bayes) have a higher asymptotic error than discriminative models (e.g., logistic regression), but they approach the asymptotic error faster. In other words, discriminative models tend to perform better given a large enough dataset while generative models will perform better on small dataset as they learn faster. Since the dataset is large, choosing a discriminative model would be more appropriate for this task.

It is also important to note that the dependent variable has more than two categories. One way to handle this is to group multiple categories together so that there are only two categories. Then we would be able to use binary logistic regression to model the relationship. While this simplifies the complexity of implementing the model itself, there will be a loss in information from merging classes, impacting the strength of the conclusions we can draw. Another option to handle multi-classification is to use multinomial logistic regression which is an extension of binary logistic regression. The basic idea of this approach is to create a binary logistic regression model for each class. Each binary logistic regression model will do a one-versus-rest prediction for the corresponding class. The class with the highest probability will be the output prediction of the multinomial model. One of the caveats of this approach is that even more data is required to provide enough information for all binary logistic regression models for each class; otherwise, this method is prone to overfitting. This is less of a concern in this case because the size of the dataset is large enough to predict 5 classes. Thus, we chose multinomial logistic regression as our model for this task.

As described in the Data Characteristics section of this report, we chose four features (age, sex, marital_status, and self_rated_health) based on their perceived impact on self-rated mental health (self_rated_mental_health). We chose age as a continuous factor as opposed to the discrete version (where age is only given in whole numbers) in the interest of accuracy and being able to provide the model with the most fine-grained ata. Sex and marital status are categorical variables due to the nature of the information they provide (you're either single, married, in a common-law partnership, separated, divorced, or widowed, there is no status that exists in-between any of these options). Although self-rated health and self-rated mental health exists in real life on a continuous scale, due to the nature of responses gathered by the 2017 GSS, self_rated_health and self_rated_mental are categorical variables with possible values such as Poor, Fair, Good, Very good, and Excellent. There is no way for us to transform the categorical responses into a continuous variable that remains true to the data collected and there isn't any need to do so because we adjusted the selection of our model accordingly.

## Mathematical Model
We fully derive the mathetical representation of the multinomial logistic regression model in the Appendix. In the interest of space, here we will just provide the equations we derived for the probability of each outcome:

$$ \Pr(Y_i = 1) = \frac{e^{\boldsymbol{\beta_1 \cdot X_i}}}{1 + \sum^{4}_{k=1} e^{\boldsymbol{\beta_k \cdot X_i}}} $$
$$ \Pr(Y_i = 2) = \frac{e^{\boldsymbol{\beta_2 \cdot X_i}}}{1 + \sum^{4}_{k=1} e^{\boldsymbol{\beta_k \cdot X_i}}} $$
$$ \Pr(Y_i = 3) = \frac{e^{\boldsymbol{\beta_3 \cdot X_i}}}{1 + \sum^{4}_{k=1} e^{\boldsymbol{\beta_k \cdot X_i}}} $$
$$ \Pr(Y_i = 4) = \frac{e^{\boldsymbol{\beta_4 \cdot X_i}}}{1 + \sum^{4}_{k=1} e^{\boldsymbol{\beta_k \cdot X_i}}}$$
$$ \Pr(Y_i = 5) = \frac{1}{1 + \sum^{4}_{k=1} e^{\boldsymbol{\beta_k \cdot X_i}}} $$
We will explain each variable that appears in the equations above (again, please see the Appendix for a more natural definition of each variable as we derive these equations). 
$Y_i$ represents the outcome of the response variable for the $i$th observation. Since we have a total of 5 possible outcomes (Poor, Fair, Good, Very Good, and Excellent), we represent each of them as 1, 2, 3, 4, and 5 in the interest of space. 

$\boldsymbol{\beta_k}$ is the row vector with elements that are the coefficients for the explanatory variables for the $k$th outcome. More explicitly, $\boldsymbol{\beta_k} = [\beta_{0,k}, \beta_{1,k}, \beta_{2,k}, \beta_{3,k}, \beta_{4,k}]$ where $\beta_{0,k}$ is the intercept for the $k$th outcome, $\beta_{1,k}$ is the coefficient for the first explanatory variable (age) for the $k$th outcome, $\beta_{2,k}$ is the coefficient for the second explanatory variable (sex) for the $k$th outcome, $\beta_{3,k}$ is the coefficient for the third explanatory variable (marital_status) for the $k$th outcome, and $\beta_{4,k}$ is the coefficient for the fourth explanatory variable (self_rated_health) for the $k$th outcome.

$\boldsymbol{x_i}$ is the row vector of explanatory variables for the $i$th observation. Specifically, $\boldsymbol{x_i} = [1, x_{1,i}, x_{2,i}, x_{3,i}, x_{4,i}]$ where $x_{1,i}$ is the value of the first explanatory variable (age) for the $i$th observation, $x_{2, i}$ is the value of the second explanatory variable (sex) for the $i$th observation, and so on.

Therefore, the first equation represents the probability that the self_rated_mental_health of the $i$th observation is Poor given values for age, sex, marital_status, and self_rated_health. The other 4 equations can be interpreted in a smiliar manner.

## Running the Model
To estimate the model, we use the multinom function from the library nnet written in the programming language R. Our script is run using the software RStudio.

-model convergence
-model checks
-diagnostic

```{r message=FALSE, warning=FALSE}
# install.packages("nnet")
library(nnet)
library(tidyverse)
model <- nnet::multinom(self_rated_mental_health ~ age + sex + marital_status + self_rated_health, 
                  data = data)
summary(model)

head(fitted(model))
input <- data.frame(self_rated_health = c("Excellent"), age = c(21.5), sex = c("Male"), marital_status = c("Single, never married"))
predict(model, newdata = input, "probs")
```

# Results
# Discussion
Predicting mental health in the context of the nuclear family. 
Does being married have a positive or negative impact?

## Weaknesses

## Next Steps

# Appendix

## Derivation of the mathematical representation of the multinomial logistic regression model
Recall that the multinomial logistic regression consists of several binary logistic regression models. Like binary logistic regression, multinomial logistic regression predicts the probability that the $i$th observation has outcome $k$ using the following function:

$$f(k, i) = \beta_{0,k} + \beta_{1,k}x_{1,i} + \beta_{2,k}x_{2,i} + ... + \beta_{M,k}x_{M,i}$$
where $\beta_{m,k}$ is the coefficient for the $m$th explanatory variable and the $k$th outcome while $x_{m, i}$ is the value of the $m$th explanatory variable for the $i$th observation. In our case, we have $M=4$ (age, sex, marital_status, self_rated_health) explanatory variables so the function as applicable to our model is:  

$$f(k, i) = \beta_{0,k} + \beta_{1,k}x_{1,i} + \beta_{2,k}x_{2,i} + \beta_{3,k}x_{3,i} + \beta_{4,k}x_{4,i}$$
Note that we can represent $\beta_{0,k}, \beta_{1,k}, \beta_{2,k}, \beta_{3,k}, \beta_{4,k}$ and $1, x_{1,i}, x_{2,i}, x_{3,i}, x_{4,i}$  as row vectors $\boldsymbol{\beta_k}$ and $\boldsymbol{x_i}$, respectively. Then, the function can be simplified as follows:
$$f(k, i) = \boldsymbol{\beta_k} \cdot \boldsymbol{x_i}$$
where we take the dot product of the two row vectors we just defined.

As previously mentioned, the multinomial logistic regression model is a series of binary logistic regressions where the probability of each outcome of the response variable (self-rated mental health) is regressed against a chosen pivot outcome. Let $Y_i$ represent the outcome of the response variable for the $i$th observation. We have a total of 5 possible outcomes (Poor, Fair, Good, Very Good, and Excellent represented as 1, 2, 3, 4, and 5, respectively). Let's choose the last outcome (Excellent or 5) as the pivot. In mathematical notation, this is:
$$ \ln{\frac{\Pr(Y_i = 1)}{\Pr(Y_i = 5)}} = \boldsymbol{\beta_1 \cdot X_i} $$
$$ \ln{\frac{\Pr(Y_i = 2)}{\Pr(Y_i = 5)}} = \boldsymbol{\beta_2 \cdot X_i} $$
$$\ln{\frac{\Pr(Y_i = 3)}{\Pr(Y_i = 5)}} = \boldsymbol{\beta_3 \cdot X_i} $$
$$\ln{\frac{\Pr(Y_i = 4)}{\Pr(Y_i = 5)}} = \boldsymbol{\beta_4 \cdot X_i} $$

Then, we solve for the probabilities by exponentiating both sides:
$$ \Pr(Y_i = 1) = \Pr(Y_i = 5) \cdot e^{\boldsymbol{\beta_1 \cdot X_i}} $$
$$ \Pr(Y_i = 2) = \Pr(Y_i = 5) \cdot e^{\boldsymbol{\beta_2 \cdot X_i}} $$
$$ \Pr(Y_i = 3) = \Pr(Y_i = 5) \cdot e^{\boldsymbol{\beta_3 \cdot X_i}}$$
$$ \Pr(Y_i = 4) = \Pr(Y_i = 5) \cdot e^{\boldsymbol{\beta_4 \cdot X_i}}$$

The probability of the pivot outcome can be calculated because we know that the probability of all outcomes must sum to 1:
$$ \Pr(Y_i = 5) = 1 - \left(\Pr(Y_i = 5) \cdot e^{\boldsymbol{\beta_1 \cdot X_i}} + \Pr(Y_i = 5) \cdot e^{\boldsymbol{\beta_2 \cdot X_i}} + \Pr(Y_i = 5) \cdot e^{\boldsymbol{\beta_3 \cdot X_i}} + \Pr(Y_i = 5) \cdot e^{\boldsymbol{\beta_4 \cdot X_i}}\right) $$
$$ 1 = \Pr(Y_i = 5) + \Pr(Y_i = 5) \cdot e^{\boldsymbol{\beta_1 \cdot X_i}} + \Pr(Y_i = 5) \cdot e^{\boldsymbol{\beta_2 \cdot X_i}} + \Pr(Y_i = 5) \cdot e^{\boldsymbol{\beta_3 \cdot X_i}} + \Pr(Y_i = 5) \cdot e^{\boldsymbol{\beta_4 \cdot X_i}} $$
$$ 1 = \Pr(Y_i = 5) \left(1 + e^{\boldsymbol{\beta_1 \cdot X_i}} + e^{\boldsymbol{\beta_2 \cdot X_i}} + e^{\boldsymbol{\beta_3 \cdot X_i}} + e^{\boldsymbol{\beta_4 \cdot X_i}} \right) $$
$$ 1 = \Pr(Y_i = 5) \left(1 + \sum^{4}_{k=1} e^{\boldsymbol{\beta_k \cdot X_i}} \right) $$
$$ \Pr(Y_i = 5) = \frac{1}{1 + \sum^{4}_{k=1} e^{\boldsymbol{\beta_k \cdot X_i}}} $$
Having the expression for $\Pr(Y_i = 4)$, we can represent the probabilities of the other outcomes as follows:
$$ \Pr(Y_i = 1) = \frac{e^{\boldsymbol{\beta_1 \cdot X_i}}}{1 + \sum^{4}_{k=1} e^{\boldsymbol{\beta_k \cdot X_i}}} $$
$$ \Pr(Y_i = 2) = \frac{e^{\boldsymbol{\beta_2 \cdot X_i}}}{1 + \sum^{4}_{k=1} e^{\boldsymbol{\beta_k \cdot X_i}}} $$
$$ \Pr(Y_i = 3) = \frac{e^{\boldsymbol{\beta_3 \cdot X_i}}}{1 + \sum^{4}_{k=1} e^{\boldsymbol{\beta_k \cdot X_i}}} $$
$$ \Pr(Y_i = 4) = \frac{e^{\boldsymbol{\beta_4 \cdot X_i}}}{1 + \sum^{4}_{k=1} e^{\boldsymbol{\beta_k \cdot X_i}}}$$
$$ \Pr(Y_i = 5) = \frac{1}{1 + \sum^{4}_{k=1} e^{\boldsymbol{\beta_k \cdot X_i}}} $$


# References
Interview method/survey size: https://www.statcan.gc.ca/eng/survey/household/4501
Detailed information about GSS 2017: https://www23.statcan.gc.ca/imdb/p2SV.pl?Function=getSurvey&Id=335816
Questionnaire: https://www23.statcan.gc.ca/imdb/p3Instr.pl?Function=assembleInstr&lang=en&Item_Id=335815#qb345205
Mental health statistics: https://www.camh.ca/en/Driving-Change/The-Crisis-is-Real/Mental-Health-Statistics
Discriminative vs Generative Classifiers (Naive Bayes vs lostic regression): https://ai.stanford.edu/~ang/papers/nips01-discriminativegenerative.pdf
Age and sex https://www12.statcan.gc.ca/census-recensement/2016/dp-pd/hlt-fst/as/Table.cfm?Lang=E&T=21